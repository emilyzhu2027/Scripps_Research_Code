{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This file calculates the correlations for the female data features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing and cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing imputed participant data on features we're interested in\n",
    "dfFemale = pd.read_csv(\"/gpfs/home/ezhu/Reprocess_NewData/Imputation (4)/final_female_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganizing the data\n",
    "dfFemale = dfFemale.sort_values(by=['eid'])\n",
    "dfFemale = dfFemale.reset_index()\n",
    "dfFemale = dfFemale.drop(columns = [\"Unnamed: 0\", \"index\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 519/519 [00:01<00:00, 466.29it/s] \n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into categorical and continuous features based on their column names\n",
    "df_contF = pd.DataFrame()\n",
    "df_catF = pd.DataFrame()\n",
    "df_catF_cols = []\n",
    "for i in tqdm(dfFemale.columns):\n",
    "    if \"_\" in str(i):\n",
    "        df_catF_cols.append(i)\n",
    "        df_catF = pd.concat([df_catF, dfFemale[i]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Cramer's V for Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical-Categorical\n",
    "# --> use corrected Cramer's V\n",
    "def cramers_V(var1,var2) :\n",
    "    crosstab =np.array(pd.crosstab(var1,var2, rownames=None, colnames=None)) # Cross table building\n",
    "    stat = chi2_contingency(crosstab)[0] # Keeping of the test statistic of the Chi2 test\n",
    "    obs = np.sum(crosstab) # Number of observations\n",
    "    mini = min(crosstab.shape)-1 # Take the minimum value between the columns and the rows of the cross table - why mini = 0??????????????\n",
    "    return np.sqrt(stat/(obs*mini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1624, 239)\n"
     ]
    }
   ],
   "source": [
    "df_Categ_F_Clean = df_catF.loc[:, (df_catF != 0).any(axis=0)]\n",
    "print(df_Categ_F_Clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239/239 [13:14<00:00,  3.32s/it]\n"
     ]
    }
   ],
   "source": [
    "columns = list(df_Categ_F_Clean.columns)\n",
    "rows= []\n",
    "\n",
    "for var1 in tqdm(columns):\n",
    "    col = []\n",
    "    for var2 in columns:\n",
    "        cramers = cramers_V(df_Categ_F_Clean[var1], df_Categ_F_Clean[var2]) # Cramer's V test\n",
    "        col.append(round(cramers,2)) # Keeping of the rounded value of the Cramer's V  \n",
    "    rows.append(col)\n",
    "\n",
    "cramers_results = np.array(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCramer_F = pd.DataFrame(cramers_results, columns = df_Categ_F_Clean.columns, index = df_Categ_F_Clean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCramer_F.to_csv(\"fem_cramersv_correlation_matrix.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Pearson's Correlation for Continuous Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous-Continuous\n",
    "# --> use Pearson's\n",
    "df_contF = dfFemale.drop(columns, axis=1)\n",
    "corr_mat = df_contF.corr(method='pearson')\n",
    "\n",
    "# pearson's correlation value will be NaN if there is no standard deviation in one of the columns\n",
    "# so, this would indicate no correlation - so i replaced the NaN with 0\n",
    "corr_mat = corr_mat.fillna(0) \n",
    "\n",
    "dfPearson_F = corr_mat.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPearson_F = dfPearson_F.drop(['eid'], axis=1)\n",
    "dfPearson_F = dfPearson_F.drop(['eid'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPearson_F.to_csv(\"fem_pearson_correlation_matrix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
